{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69280e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.efficient_kan.kan import KAN\n",
    "from src.efficient_kan.functions import evaluate, save_kan_model, load_kan_model, data_subset\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import os\n",
    "os.chdir(\"/workspaces/efficient-kan\")\n",
    "sys.path.append(os.path.abspath(\"./src\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "062f5d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  \n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "full_trainset = torchvision.datasets.MNIST(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "full_valset = torchvision.datasets.MNIST(\n",
    "    root=\"./data\", train=False, download=True, transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2e63709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 60000 training samples out of 60000 total\n",
      "Using 10000 validation samples out of 10000 total\n"
     ]
    }
   ],
   "source": [
    "#Subsets of the data\n",
    "trainset = data_subset(full_trainset, 1)\n",
    "valset = data_subset(full_valset, 1)\n",
    "print(f\"Using {len(trainset)} training samples out of {len(full_trainset)} total\")\n",
    "print(f\"Using {len(valset)} validation samples out of {len(full_valset)} total\")\n",
    "\n",
    "#Data Loaders\n",
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "valloader = DataLoader(valset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af3a7d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for KAN:\n\tMissing key(s) in state_dict: \"layers.0.spline_scaler\", \"layers.1.spline_scaler\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m model = KAN([\u001b[32m28\u001b[39m * \u001b[32m28\u001b[39m, \u001b[32m64\u001b[39m, \u001b[32m10\u001b[39m])\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m#Load the model?\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m model = \u001b[43mload_kan_model\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./model/truekan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m#Other Variables\u001b[39;00m\n\u001b[32m      8\u001b[39m device = torch.device(\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/efficient-kan/src/efficient_kan/functions.py:44\u001b[39m, in \u001b[36mload_kan_model\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mefficient_kan\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkan\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KAN  \u001b[38;5;66;03m# Import here to avoid circular imports\u001b[39;00m\n\u001b[32m     32\u001b[39m model = KAN(\n\u001b[32m     33\u001b[39m     layers_hidden=config[\u001b[33m'\u001b[39m\u001b[33mlayers_hidden\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     34\u001b[39m     grid_size=config[\u001b[33m'\u001b[39m\u001b[33mgrid_size\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     41\u001b[39m     grid_range=config[\u001b[33m'\u001b[39m\u001b[33mgrid_range\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     42\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/torch/nn/modules/module.py:2593\u001b[39m, in \u001b[36mModule.load_state_dict\u001b[39m\u001b[34m(self, state_dict, strict, assign)\u001b[39m\n\u001b[32m   2585\u001b[39m         error_msgs.insert(\n\u001b[32m   2586\u001b[39m             \u001b[32m0\u001b[39m,\n\u001b[32m   2587\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2588\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[32m   2589\u001b[39m             ),\n\u001b[32m   2590\u001b[39m         )\n\u001b[32m   2592\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2593\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   2594\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2595\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m, \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m\"\u001b[39m.join(error_msgs)\n\u001b[32m   2596\u001b[39m         )\n\u001b[32m   2597\u001b[39m     )\n\u001b[32m   2598\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[31mRuntimeError\u001b[39m: Error(s) in loading state_dict for KAN:\n\tMissing key(s) in state_dict: \"layers.0.spline_scaler\", \"layers.1.spline_scaler\". "
     ]
    }
   ],
   "source": [
    "#Initialize the model\n",
    "model = KAN([28 * 28, 64, 10])\n",
    "\n",
    "#Load the model?\n",
    "#model = load_kan_model(\"./model/any\")\n",
    "\n",
    "#Other Variables\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.8)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d80c5cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss: 0.13927828586529822, Total Accuracy: 0.9570063694267515\n"
     ]
    }
   ],
   "source": [
    "#Initial evaluation\n",
    "fullloader = DataLoader(full_valset, batch_size=64, shuffle=False)\n",
    "total_loss, total_accuracy = evaluate(fullloader, model, criterion)\n",
    "print(f\"Total Loss: {total_loss}, Total Accuracy: {total_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3324496d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:27<00:00, 33.88it/s, accuracy=0.969, loss=0.107, lr=0.001] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Val Loss: 0.13094316027868705, Val Accuracy: 0.9596934713375797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:26<00:00, 35.95it/s, accuracy=0.969, loss=0.0711, lr=0.0008]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Val Loss: 0.11488506491859532, Val Accuracy: 0.9647691082802548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:26<00:00, 35.13it/s, accuracy=0.969, loss=0.166, lr=0.00064] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Val Loss: 0.10752356418402521, Val Accuracy: 0.9675557324840764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:25<00:00, 36.13it/s, accuracy=0.969, loss=0.132, lr=0.000512] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Val Loss: 0.09236083468007054, Val Accuracy: 0.9720342356687898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:25<00:00, 36.71it/s, accuracy=1, loss=0.0159, lr=0.00041]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Val Loss: 0.09315305239087932, Val Accuracy: 0.971437101910828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:25<00:00, 36.12it/s, accuracy=1, loss=0.00473, lr=0.000328]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Val Loss: 0.08997582893812685, Val Accuracy: 0.9739251592356688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:27<00:00, 34.03it/s, accuracy=1, loss=0.0321, lr=0.000262]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Val Loss: 0.09081262281716201, Val Accuracy: 0.9735270700636943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:26<00:00, 36.04it/s, accuracy=1, loss=0.00338, lr=0.00021]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Val Loss: 0.0895675291703231, Val Accuracy: 0.9743232484076433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:26<00:00, 36.04it/s, accuracy=1, loss=0.0019, lr=0.000168]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Val Loss: 0.08938034130987017, Val Accuracy: 0.9740246815286624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:27<00:00, 34.00it/s, accuracy=1, loss=0.00176, lr=0.000134]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Val Loss: 0.08996701971286683, Val Accuracy: 0.9741242038216561\n"
     ]
    }
   ],
   "source": [
    "#Train the model\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    with tqdm(trainloader) as pbar:\n",
    "        for i, (images, labels) in enumerate(pbar):\n",
    "            images = images.view(-1, 28 * 28).to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(images)\n",
    "            loss = criterion(output, labels.to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            accuracy = (output.argmax(dim=1) == labels.to(device)).float().mean()\n",
    "            pbar.set_postfix(loss=loss.item(), accuracy=accuracy.item(), lr=optimizer.param_groups[0]['lr'])\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss, val_accuracy = evaluate(valloader, model, criterion)\n",
    "    scheduler.step()\n",
    "    print(f\"Epoch {epoch + 1}, Val Loss: {val_loss}, Val Accuracy: {val_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f809ed98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss: 0.08996594905060609, Total Accuracy: 0.9741242038216561\n"
     ]
    }
   ],
   "source": [
    "#Save and more evaluation\n",
    "save_kan_model(model, path=\"./model/loadmodel\")\n",
    "fullloader = DataLoader(full_valset, batch_size=64, shuffle=False)\n",
    "total_loss, total_accuracy = evaluate(fullloader, model, criterion)\n",
    "print(f\"Total Loss: {total_loss}, Total Accuracy: {total_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
